HTTP는 TCP 바로 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 그 아래 계층인 TCP 성능에 영향을 받는다.

## 1. HTTP 트랜잭션 지연

<img width="500" alt="" src="https://github.com/user-attachments/assets/96a3239c-9ff1-4803-b405-7785de56bc9c" />

트랜잭션을 처리하는 시간은 TCP 커넥션을 설정하고, 요청을 전송하고, 응답 메시지를 보내는 것에 비하면 상당히 짧다는 것을 알 수 있다.

클라이언트나 서버가 너무 많은 데이터를 내려받거나 복잡하고 동적인 자원들을 실행하지 않는 한, 대부분의 HTTP 지연은 TCP 네트워크 지연 때문에 발생한다.

HTTP 트랜잭션을 지연시키는 원인은 여러 가지가 있다.

> 1. 클라이언트는 URI에서 웹 서버의 IP 주소와 포트 번호를 알아내야 한다.

만약 URI에 기술되어 있는 호스트에 방문한 적이 최근에 없으면, DNS 이름 분석(DNS resolution) 인프라를 사용하여 URI에 있는 호스트 명을 IP 주소로 변환하는데 수십 초의 시간이 걸릴 것이다.

> 2. 다음으로, 클라이언트는 TCP 커넥션 요청을 서버에게 보내고 서버가 커넥션 허가 응답을 회신하기를 기다린다.

커넥션 설정 시간은 새로운 TCP 커넥션에서 항상 발생한다.

이는 보통 1~2초의 시간이 소요되지만, 수백 개의 HTTP 트랜잭션이 만들어지면 소요시간은 크게 증가할 것이다.

> 3. 커넥션이 맺어지면 클라이언트는 HTTP 요청을 새로 생성된 TCP 파이프를 통해 전송한다.

웹 서버는 데이터가 도착하는 대로 TCP 커넥션에서 요청 메시지를 읽고 처리한다.

요청 메시지가 인터넷을 통해 전달되고 서버에 의해서 처리되는 데까지는 시간이 소요된다.

> 4. 웹 서버가 HTTP 응답을 보내는 것 역시 시간이 소요된다.

## 2. 성능 관련 중요 요소

여기서부터는, 다음과 같은 요인과 그로 인한 성능상의 문제를 포함해 HTTP 프로그래머에게 영향을 주는 가장 일반적인 TCP 관련 지연들에 대해 간략히 다룰 것이다.

- TCP 커넥션의 핸드셰이크 설정
- 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
- 데이터를 한데 모아 한 번에 전송하기 위한 네이글(nagle) 알고리즘
- TCP의 편승(piggyback) 확인응답(acknowledgement)을 위한 확인응답 지연 알고리즘
- TIME_WAIT 지연과 포트 고갈

## 3. TCP 커넥션 핸드셰이크 지연

어떤 데이터를 전송하든 새로운 TCP 커넥션을 열 때면, TCP 소프트웨어는 커넥션을 맺기 위한 조건을 맞추기 위해 연속으로 IP 패킷을 교환한다.

작은 크기의 데이터 전송에 커넥션이 사용된다면 이런 패킷 교환은 HTTP 성능을 크게 저하시킬 수 있다.

다음은 TCP 커넥션이 핸드셰이크를 하는 순서다.

1. 클라이언트는 새로운 TCP 커넥션을 생성하기 위해 작은 TCP 패킷(보통 40~60바이트)을 서버에게 보낸다. 그 패킷은 'SYN'라는 특별한 플래그를 가지는데, 이 요청이 커넥션 생성 요청이라는 뜻이다.
2. 서버가 그 커넥션을 받으면 몇 가지 커넥션 매개변수를 산출하고, 커넥션 요청이 받아들여졌음을 의미하는 'SYN'과 'ACK' 플래그를 포함한 TCP 패킷을 클라이언트에게 보낸다.
3. 마지막으로 클라이언트는 커넥션이 잘 맺어졌음을 알리기 위해서 서버에게 다시 확인응답 신호를 보낸다. 오늘날의 TCP는 클라이언트가 이 확인응답 패킷과 함께 데이터를 보낼 수 있다.

HTTP 프로그래머는 이 패킷들을 보지 못한다(패킷들은 보이지 않게 TCP 소프트웨어가 관리한다).

HTTP 프로그래머가 보는 것은 새로운 TCP 커넥션이 생성될 때 발생하는 지연이 전부다.

HTTP 트랜잭션이 아주 큰 데이터를 주고받지 않는 평범한 경우에는, SYN/SYN+ACK 핸드셰이크가 눈에 띄는 지연을 발생시킨다.

**결국, 크기가 작은 HTTP 트랜잭션은 50% 이상의 시간을 TCP를 구성하는 데 쓴다.**

이후 절에서는 이러한 TCP 구성으로 인한 지연을 제거하기 위해서 HTTP가 이미 존재하는 커넥션을 어떻게 재활용하는지 알아볼 것이다.

## 4. 확인응답 지연

인터넷 자체가 패킷 전송을 완벽히 보장하지는 않기 때문에(인터넷 라우터는 과부하가 걸렸을 때 패킷을 마음대로 파기할 수 있다), TCP는 성공적인 데이터 전송을 보장하기 위해서 자체적인 확인 체계를 가진다.

각 TCP 세그먼트는 순번과 데이터 무결성 체크섬을 가진다.

각 세그먼트의 수신자는 세그먼트를 온전히 받으면 작은 확인응답 패킷을 송신자에게 반환한다.

만약 송신자가 특정 시간 안에 확인응답 메시지를 받지 못하면 패킷이 파기되었거나 오류가 있는 것으로 판단하고 데이터를 다시 전송한다.

**확인응답은 그 크기가 작기 때문에, TCP는 같은 방향으로 송출되는 데이터 패킷에 확인응답을 '편승(piggyback)'시킨다.**

TCP는 송출 데이터 패킷과 확인응답을 하나로 묶음으로써 네트워크를 좀 더 효율적으로 사용한다.

확인응답이 같은 방향으로 가는 데이터 패킷에 편승되는 경우를 늘리기 위해서, 많은 TCP 스택은 '확인응답 지연' 알고리즘을 구현한다.

**확인응답 지연은 송출할 확인응답을 특정 시간 동안(보동 0.1~0.2초) 버퍼에 저장해 두고, 확인응답을 편승시키기 위한 송출 데이터 패킷을 찾는다.**

**만약 일정 시간 안에 송출 데이터 패킷을 찾지 못하면 확인응답은 별도 패킷을 만들어 전송된다.**

안타깝게도 요청과 응답 두 가지 형식으로만 이루어지는 HTTP 동작 방식은, 확인 응답이 송출 데이터 패킷에 편승할 기회를 감소시킨다.

**막상 편승할 패킷을 찾으려고 하면 해당 방향으로 송출될 패킷이 많지 않기 때문에, 확인응답 지연 알고리즘으로 인한 지연이 자주 발생한다.**

운영체제에 따라 다르지만, 지연의 원인이 되는 확인응답 지연 관련 기능을 수정하거나 비활성화할 수 있다.

## 5. TCP 느린 시작(slow start)

TCP의 데이터 전송 속도는 TCP 커넥션이 만들어진 지 얼마나 지났는지에 따라 달라질 수 있다.

**TCP 커넥션은 시간이 지나면서 자체적으로 '튜닝'되어서, 처음에는 커넥션의 최대 속도를 제한하고 데이터가 성공적으로 전송됨에 따라서 속도 제한을 높여나간다.**

**이렇게 조율하는 것을 TCP 느린 시작이라고 부르며, 이는 인터넷의 급작스러운 부하와 혼잡을 방지하는 데 쓰인다.**

**TCP 느린 시작은 TCP가 한 번에 전송할 수 있는 패킷의 수를 제한한다.**

간단히 말해서, 패킷이 성공적으로 전달되는 각 시점에 송신자는 추가로 2개의 패킷을 더 전송할 수 있는 권한을 얻는다.

HTTP 트랜잭션에서 전송할 데이터의 양이 많으면 모든 패킷을 한 번에 전송할 수 없다.

그 대신 한 개의 패킷만 전송하고 확인응답을 기다려야 한다.

확인응답을 받으면 2개의 패킷을 보낼 수 있으며, 그 패킷 각각 대한 확인응답을 받으면 총 4개의 패킷을 보낼 수 있게 된다.

이를 '혼잡 윈도를 연다(opening the congestion window)'라고 한다.

**이 혼잡제어 기능 때문에, 새로운 커넥션은 이미 어느 정도 데이터를 주고받은 '튜닝'된 커넥션보다 느리다.**

**'튜닝'된 커넥션은 더 빠르기 때문에, HTTP에는 이미 존재하는 커넥션을 재사용하는 기능이 있다.**

## 6. 네이글(Nagle) 알고리즘과 TCP_NODELAY

애플리케이션이 어떤 크기의 데이터든지(심지어 1바이트라도) TCP 스택으로 전송할 수 있도록, TCP는 데이터 스트림 인터페이스를 제공한다.

**하지만 각 TCP 세그먼트는 40바이트 상당의 플래그와 헤더를 포함하여 전송하기 때문에, TCP가 작은 크기의 데이터를 포함한 많은 수의 패킷을 전송한다면 네트워크 성능은 크게 떨어진다.**

**네이글 알고리즘(알고리즘을 만들어낸 존 네이글(John Nagle)의 이름을 따서 만들어졌다)은 네트워크 효율을 위해서, 패킷을 전송하기 전에 많은 양의 TCP 데이터를 한 개의 덩어리로 합친다.**

**네이글 알고리즘은 세그먼트가 최대 크기(패킷의 최대 크기는 LAN상에서 1,500바이트 정도, 인터넷상에서는 수백 바이트 정도다)가 되지 않으면 전송을 하지 않는다.**

다만 다른 모든 패킷이 확인응답을 받았을 경우에는 최대 크기보다 작은 패킷의 전송을 허락한다.

다른 패킷들이 아직 전송 중이면 데이터는 버퍼에 저장된다.

전송되고 나서 확인응답을 기다리던 패킷이 확인응답을 받았거나 전송하기 충분할 만큼의 패킷이 쌓였을 때 버퍼에 저장되어 있던 데이터가 전송된다.

네이글 알고리즘은 HTTP 성능 관련해 여러 문제를 발생시킨다.

첫 번째로, 크기가 작은 HTTP 메시지는 패킷을 채우지 못하기 때문에, 앞으로 생길지 생기지 않을지 모르는 추가적인 데이터를 기다리며 지연될 것이다.

두 번째로, 네이글 알고리즘은 확인응답 지연과 함께 쓰일 경우 형편없이 동작한다.

네이글 알고리즘은 확인응답이 도착할 때까지 데이터를 전송을 멈추고 있는 반면, 확인응답 지연 알고리즘은 확인응답을 100~200밀리초 지연시킨다.

HTTP 애플리케이션은 성능 향상을 위해서 HTTP 스택에 TCP_NODELAY 파라미터 값을 설정하여 네이글 알고리즘을 비활성화하기도 한다.

이 설정을 했다면, 작은 크기의 패킷이 너무 많이 생기지 않도록 큰 크기의 데이터 덩어리를 만들어야 한다.

## 7. TIME_WAIT의 누적과 포트 고갈

TIME_WAIT 포트 고갈은 성능 측정 시에 심각한 성능 저하를 발생시키지만, 보통 실제 상황에서는 문제를 발생시키지 않는다.

하지만 성능 측정을 하는 사람이라면, 결국에는 이 문제에 봉착하게 될 것이고 생각하지도 못했던 성능상의 문제가 생긴 것으로 오해할 수 있으니 특별히 조심해야 한다.

**TCP 커넥션의 종단에서 TCP 커넥션을 끊으면, 종단에서는 커넥션의 IP 주소와 포트 번호를 메모리의 작은 제어영역(control block)에 기록해 놓는다.**

**이 정보는 같은 주소와 포트 번호를 사용하는 새로운 TCP 커넥션이 일정 시간 동안에는 생성되지 않게 하기 위한 것으로, 보통 세그먼트의 최대 생명주기에 두 배 정도('2MSL'이라고 불리며 보통 2분 정도)의 시간 동안만 유지된다.**

**이는 이전 커넥션과 관련된 패킷이 그 커넥션과 같은 주소와 포트 번호를 가지는 새로운 커넥션에 삽입되는 문제를 방지한다.**

**실제로 이 알고리즘은 특정 커넥션이 생성되고 닫힌 다음, 그와 같은 IP 주소와 포트 번호를 가지는 커넥션이 2분 이내에 또 생성되는 것을 막아준다.**

현대의 빠른 라우터들 덕분에 커넥션이 닫힌 후에 중복되는 패킷이 생기는 경우는 거의 없어졌다.

2MSL을 더 짧은 값으로 수정하는 운영체제도 있지만, 이 값 수정은 조심해야 한다.

만약 이전 커넥션의 패킷이 그 커넥션과 같은 연결 값으로 생성된 커넥션에 삽입되면, 패킷은 중복되고 TCP 데이터는 충돌할 것이다.

**일반적으로 2MSL의 커넥션 종료 지연이 문제가 되지는 않지만, 성능시험을 하는 상황에서는 문제가 될 수 있다.**

**성능 측정 대상 서버는 클라이언트가 접속할 수 있는 IP 주소의 개수를 제한하고, 그 서버에 접속하여 부하를 발생시킬 컴퓨터의 수는 적기 때문이다.**

게다가 일반적으로 서버는 HTTP의 기본 TCP 포트인 80번을 사용한다.

이런 상황에서는 가능한 연결의 조합이 제한되며, TIME_WAIT로 인해서 순간순간 포트를 재활용하는 것이 불가능해진다.

각각 한 개의 클라이언트와 웹 서버가 있고, TCP 커넥션을 맺기 위한 네 개의 값이 있다고 해보자.

`<발신지 IP 주소, 발신지 포트, 목적지 IP 주소, 목적지 포트>`

이 중에서 세 개는 고정되어 있고 발신지 포트만 변경할 수 있다.

`<클라이언트 IP, 발신지 포트, 서버 IP, 80>`

클라이언트가 서버에 접속할 때마다, 유일한 커넥션을 생성하기 위해서 새로운 발신지 포트를 쓴다.

하지만 사용할 수 있는 빌신지 포트의 수는 제한되어 있고(60,000개로 가정) 2MSL초 동안(120초로 가정) 커넥션이 재사용될 수 없으므로, 초당 500개(60,000 / 120 = 500)로 커넥션이 제한된다.

서버가 초당 500개 이상의 트랜잭션을 처리할 만큼 빠르지 않다면 TIME_WAIT 포트 고갈은 일어나지 않는다.

이 문제를 해결하기 위해 부하를 생성하는 장비를 더 많이 사용하거나 클라이언트와 서버가 더 많은 커넥션을 맺을 수 있도록 여러 개의 가상 IP 주소를 쓸 수도 있다.

포트 고갈 문제를 겪지 않더라도, 커넥션을 너무 많이 맺거나 대기 상태로 있는 제어 블록이 너무 많아지는 상황은 주의해야 한다.

커넥션이나 제어 블록이 너무 많이 생기면 극심하게 느려지는 운영체제도 있다.
