PO는 고객 경험을 개선하기 위한 여러 가지 방법 중 최적인 것을 가설로 선택한 후, 검증을 거쳐 선보인다.

이때 가설을 검증하는 방법 중 널리 사용되는 것이 A/B 테스트다.

**새로운 디자인이나 기능에 노출된 B그룹 고객들이 A그룹과 비교했을 때 어떤 결과를 나타내는지 확인해보는 테스트다.**

그것에 노출된 B그룹의 수치가 A그룹보다 유의미하게 향상되었을 경우 가설은 증명되었다고 판단한다.

**새로 개발된 기능을 배포한 후, 점차적으로 A그룹과 B그룹이 각각 50%씩의 트래픽을 수용하게 되면 본격적인 테스트를 할 준비는 완료된다.**

---

**유의 확률을 뜻하는 Probability Value의 줄임말은 P값(P-Value)은, 쉽게 말해 실험의 결과가 우연히 나타난 것인지 아닌지 판단할 때 사용되는 수치다.**

당연히 A/B 테스트의 통계적 유의도(Statistical Significance)가 100%에 가까워야 신뢰할 수 있다.

**이 통계적 유의도를 산출하려면, 1에서 P값을 빼야 한다.**

만약 어떤 A/B 테스트를 진행했는데, P값이 0.02가 나왔다고 가정해보자. 1에서 0.02를 빼면 0.98이 된다. 즉 98%의 통계적 유의도를 가졌다는 의미다.

**PO는 P값을 보며 테스트 결과를 판단해야 한다. P값이 0으로 수렴할수록 A/B 테스트의 통계적 유의도는 100%에 가까워진다.**

내가 사용하는 A/B 테스트 플랫폼은 P값이 일정 기간에 걸쳐 매우 낮게 수렴하는 트렌드를 보일 때, 그게 유의미하다고 표기해준다.

**만약 이런 기능이 없을 경우, 나는 P값이 0.01보다 낮을 때까지 테스트를 신뢰하지 않는다.**

주로 B그룹이 이겼다고 판정하고 새로운 기능을 모든 고객에게 노출할 때, 대부분의 주요 수치의 P값이 0.01보다도 훨씬 낮은 0.001이었다.

통계적 유의도가 99.9%라는 의미로, 우연한 결과가 아니었다는 것을 증명한다.

---

**PO는 A/B 테스트를 설계할 때, 어떤 수치를 봐야 할지 결정해야 한다.**

**각각 수치마다 P값을 보고 유의미한지 판단해야 하기 때문이다.**

성공 지표만 사용할 수도 있지만, 새로운 기능이 끼치는 영향을 세밀하게도 보고, 거시적으로도 보려면 다음과 같이 두 가지 타입의 지표를 모두 봐야 한다.

| | 종류 | 예시 |
| --- | --- | --- |
| 1 | 특정 기능과 직결된 수치 | - 동영상의 볼륨 조절 버튼을 사용한 평균 횟수<br>- 주문 화면의 메모 기능을 사용한 빈도<br>- 코멘트의 추천 버튼을 누른 횟수 |
| 2 | 프로덕트 전반의 수치 | - 고객 1인당 주문 횟수<br>- 고객 1인당 동영상 시청 횟수<br>- 고객 1인당 이미지 업로드 횟수 |

예를 들어, 음식 배달 서비스 앱에서 주문 화면 디자인 개편을 했다고 가정해보자. P값은 모두 0.001이다.

<img width="500" alt="" src="https://github.com/user-attachments/assets/7ddde9f0-2f76-4d76-b31f-39fb5549f881" />

첫 번째 시나리오에서는 B그룹의 메모 기능 사용 빈도가 월등히 높아졌다. 하지만 고객 1인당 평균 매출이 12,300원으로 감소했다.

두 번째 시나리오에서는 B그룹의 메모 기능 사용 빈도가 조금 더 낮아졌다. 그런데 고객 1인당 평균 매출이 19,500원으로 16%나 증가했다.

**만약 프로덕트 전반의 수치를 안 보고, 특정 기능에 대한 수치만 테스트했다면 분명 PO는 첫 번째 시나리오에서 만세를 하고 B그룹이 이겼다며 신규 디자인을 전체 적용했을 것이다.**

프로덕트 전체의 지표인 평균 매출을 보지 않았기 때문이다.

**원인 불문하고, 프로덕트의 성공 척도 중 하나인 평균 매출이 급격하게 감소했으면 테스트를 중단했어야 한다.**

**반대로 만약 PO가 기능 관련 수치와 프로덕트 전체의 지표를 모두 봤다면, 시나리오 1에서는 테스트를 중단하고 시나리오 2에서는 B그룹이 이겼다고 판단했을 것이다.**

시나리오 2에서 비록 메모 기능 사용 빈도는 조금 줄어들었지만, 메모 기능 사용을 활성화하는 것보다 주문을 더 많이 하는 게 프로덕트의 성공에는 더 큰 도움이 되기 때문이다.

---

A/B 테스트는 유의미한 사용자가 각 그룹에 노출될 때까지 기다리도록 한다.

**새로운 기능을 배포한 후, 점차 B그룹의 노출 비율을 높여가며 A그룹과 B그룹이 각각 50%가 될 때부터 테스트를 본격적으로 시작한다고 봐야 한다.**

**그때부터 최소 7일 이상을 기다리면서 각 주요 수치별 P값을 지켜보며 테스트를 중단할지 이어갈지 결정한다.**

만약 P값이 낮아지지 않아 유의미한 결과를 얻을 수 없다면, PO는 여러 가지 선택지 중 하나를 신속하게 택하도록 한다.

- 더 많은 고객에게 노출될 때까지 테스트를 며칠 더 진행해본다.
- 테스트를 중단한 후 신규 디자인 또는 기능이 의미 없다고 판단한다.
- 유의미한 결과가 없었으나, 프로덕트 전체에 악영향을 끼치지 않아 B그룹이 이겼다고 판정한다.

마지막의 경우에는 데이터를 더 세밀하게 봐야 한다.

A/B 테스트 플랫폼에서 트래킹하는 수치 이외에도, 애널리스트의 도움을 받아 다른 지표를 추가적으로 검토해보도록 하자.

**P값을 무시하면서까지 B그룹을 선정하려면, PO는 매우 많은 책임을 져야 하기 때문이다.**

**새로운 디자인이나 기능을 선보이기 전, A/B 테스트를 활용하는 것은 거의 필수적인 요소다.**

PO가 내세운 가설이 맞는지 증명하는 것은 물론, 고객 모두에게 선보여도 큰 문제가 발생하지 않을 거라는 확신을 얻을 수 있기 때문이다.
